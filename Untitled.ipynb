{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "import matploblib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# import necessary libraries\n",
    "torch.manual(111)\n",
    "# random generator seed\n",
    "\n",
    "train_data_length = 1024\n",
    "train_data = torch.zeros((train_data_length), 2)\n",
    "train_data[:, 0] = 2 * math.pi * torch.rand(train_data-length)\n",
    "train_data[:, 1] = torch.sin(train_data[:, 0])\n",
    "train_labels = torch.zeros(train_data_length)\n",
    "train_set = [\n",
    "    (train_data[i], train_labels[i]) for i in range(train_data_length)\n",
    "]\n",
    "\n",
    "# preparing training data\n",
    "\n",
    "plt.plot(train_data[:, 0], train_data[:,1], \".\")\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64,1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2),\n",
    "        )\n",
    "    def froward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "generator = Generator()\n",
    "\n",
    "lr = 0.001\n",
    "num_epochs = 300\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n, (real_samples, _) in enumerate(train_loader):\n",
    "        real_samples = real_sampels.to(device=device)\n",
    "        real_samples_labels = torch.ones((batch_size,1)).to(\n",
    "            device=device\n",
    "        )\n",
    "        latent_space_samples = torch.randn((batch_size, 100)).to(\n",
    "            device=device\n",
    "        )\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        generated_samples_labels = torch.zeros((batch_size, 1)).to(\n",
    "            device=device\n",
    "        )\n",
    "        all_samples = torch.cat((real_samples, generated_samples))\n",
    "        all_samples_labels = torch.cat(\n",
    "            (real_samples_labels, generated_samples_labels)\n",
    "        )\n",
    "\n",
    "        # Training the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        output_discriminator = discriminator(all_samples)\n",
    "        loss_generator = loss_function(\n",
    "            output_discriminator_generated, real_samples_labels\n",
    "        )\n",
    "        loss_generator.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        # Show loss\n",
    "        if epoch % 10 == 0 and n == batch_size - 1:\n",
    "            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n",
    "            print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")\n",
    "\n",
    "latent_space_samples = torch.randn(100,2)\n",
    "generated_samples = generator(latent_space_samples)\n",
    "\n",
    "generated_samples = generated_samples.detach()\n",
    "plt.plot(generated_samples[:, 0]. generated_samples[:, 1], \".\")\n",
    "\n",
    "torch.amnual_seed(111)\n",
    "\n",
    "device = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))]\n",
    ")\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root=\".\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size = batch_size, shuffle = True\n",
    ")\n",
    "\n",
    "real_samples, mnist_labels =  next(iter(train_loader))\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(real_samples[i].reshape(28,28), cmap=\"gray_r\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "discriminator = Discriminator().to(device=device)\n",
    "generator = Generator().to(device=device)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
